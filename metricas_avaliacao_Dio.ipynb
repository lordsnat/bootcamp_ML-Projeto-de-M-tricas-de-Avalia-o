{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lordsnat/bootcamp_ML-Projeto-de-M-tricas-de-Avalia-o/blob/main/metricas_avaliacao_Dio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SSgecvcog0Wo"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "#if using Theano with GPU\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zk7fZoPng63t"
      },
      "outputs": [],
      "source": [
        "#Dataset composto por uma pasta zipada dentro do drive\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "!unzip -q \"/content/drive/MyDrive/Dio.me/Transfer_Learning/PetImages.zip\" -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWZZjxedtkw",
        "outputId": "ded34d25-fdc9-45ee-d855-6ef2f4d35f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK (decodificou): 24824\n",
            "Arquivos problemáticos: 178\n",
            "BAD: /content/PetImages/Dog/7739.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/8641.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/719.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/11692.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/4203.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/3927.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/9640.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/4924.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/6503.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/6855.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/11166.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/6500.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/7128.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/7718.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/7652.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/5955.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/6555.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/8126.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/10173.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/1884.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/2353.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/10733.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/11253.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/5243.jpg -> InvalidArgumentError()\n",
            "BAD: /content/PetImages/Dog/Thumbs.db -> unsupported/hidden/empty\n"
          ]
        }
      ],
      "source": [
        "#Código verifica se há erros de formato nas imagens extraídas do dataset\n",
        "\n",
        "import tensorflow as tf\n",
        "import pathlib, os\n",
        "\n",
        "root = pathlib.Path(\"/content/PetImages\")  # ajuste se for outra pasta\n",
        "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "\n",
        "bad = []\n",
        "total_ok = 0\n",
        "\n",
        "for p in root.rglob(\"*\"):\n",
        "    if not p.is_file():\n",
        "        continue\n",
        "    ext = p.suffix.lower()\n",
        "\n",
        "    #Remove arquivos com extensões não suportadas, ocultos, tamanho 0, etc.\n",
        "    if (ext not in valid_ext) or p.name.startswith((\"._\", \".\")) or os.path.getsize(p) == 0:\n",
        "        bad.append((str(p), \"unsupported/hidden/empty\"))\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        raw = tf.io.read_file(str(p))\n",
        "        #Tenta decodificar explicitamente conforme a extensão (mais estável)\n",
        "        if ext in {\".jpg\", \".jpeg\"}:\n",
        "            _ = tf.image.decode_jpeg(raw, channels=3)\n",
        "        elif ext == \".png\":\n",
        "            _ = tf.image.decode_png(raw, channels=3)\n",
        "        elif ext == \".gif\":\n",
        "            _ = tf.image.decode_gif(raw)  #Retorna [num_frames, H, W, 3]\n",
        "        elif ext == \".bmp\":\n",
        "            _ = tf.image.decode_bmp(raw)\n",
        "        total_ok += 1\n",
        "    except Exception as e:\n",
        "        bad.append((str(p), repr(e)))\n",
        "\n",
        "print(f\"OK (decodificou): {total_ok}\")\n",
        "print(f\"Arquivos problemáticos: {len(bad)}\")\n",
        "for path, err in bad[:25]:\n",
        "    print(\"BAD:\", path, \"->\", err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goiDM_b7uat2",
        "outputId": "56d0eecb-f65e-465a-88f1-f9d1f5d09f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remoção concluída.\n"
          ]
        }
      ],
      "source": [
        "#Remove os casos problemáticos\n",
        "for path, _ in bad:\n",
        "    try:\n",
        "        os.remove(path)\n",
        "    except Exception as e:\n",
        "        print(\"Falha ao remover:\", path, e)\n",
        "print(\"Remoção concluída.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9FngxvAeJ07",
        "outputId": "b442418b-1c4e-4166-b949-399db08884c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset criado em: /content/PetImages_small\n"
          ]
        }
      ],
      "source": [
        "#Como a base PetImages é muito pesada, cria um subset menor com algumas amostras desse dataset\n",
        "import shutil, random\n",
        "\n",
        "orig = pathlib.Path(\"/content/PetImages\")\n",
        "small = pathlib.Path(\"/content/PetImages_small\")\n",
        "for cls in [\"Cat\", \"Dog\"]:\n",
        "    (small/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#Pegue no máx N por classe\n",
        "N = 1500\n",
        "random.seed(42)\n",
        "\n",
        "for cls in [\"Cat\", \"Dog\"]:\n",
        "    files = [p for p in (orig/cls).glob(\"*\") if p.is_file()]\n",
        "    random.shuffle(files)\n",
        "    kept = 0\n",
        "    for p in files:\n",
        "        if kept >= N: break\n",
        "        #Copia apenas extensões suportadas\n",
        "        if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"} and os.path.getsize(p) > 0:\n",
        "            shutil.copy2(p, small/cls/p.name)\n",
        "            kept += 1\n",
        "\n",
        "print(\"Subset criado em:\", small)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7w6E6Rugtxu",
        "outputId": "40d62464-b7bb-414e-d802-003938754fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 2 classes.\n",
            "Using 2550 files for training.\n",
            "Found 3000 files belonging to 2 classes.\n",
            "Using 450 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-1601805001.py:17: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Cat', 'Dog']\n"
          ]
        }
      ],
      "source": [
        "root_dir = \"/content/PetImages_small\"\n",
        "\n",
        "# 1) Cria os datasets brutos e capture class_names\n",
        "train_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    root_dir, validation_split=0.15, subset=\"training\",\n",
        "    seed=42, image_size=(224,224), batch_size=8, shuffle=True\n",
        ")\n",
        "val_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    root_dir, validation_split=0.15, subset=\"validation\",\n",
        "    seed=42, image_size=(224,224), batch_size=8\n",
        ")\n",
        "\n",
        "class_names = train_raw.class_names   # <-- capture aqui\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# 2) Aplica cache/prefetch/ignore_errors\n",
        "train_ds = train_raw.cache().prefetch(tf.data.AUTOTUNE).apply(tf.data.experimental.ignore_errors())\n",
        "val_ds   = val_raw.cache().prefetch(tf.data.AUTOTUNE).apply(tf.data.experimental.ignore_errors())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XItZgZeAodvM"
      },
      "source": [
        "*Camadas de preparação + carregar VGG16*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SV1K_XejdgO",
        "outputId": "5901770e-cb8e-4a07-8694-fc2cae569841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de classes: 2\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "print(\"Número de classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmrpS4EOngwQ",
        "outputId": "b8cf1353-a851-4a4f-e0a8-12f9cd9d501f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "NUM_CLASSES = num_classes\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "preprocess = layers.Rescaling(1./255)\n",
        "\n",
        "#Base VGG16 pré-treinada no ImageNet, sem o topo\n",
        "base = applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=IMG_SIZE + (3,)\n",
        ")\n",
        "base.trainable = False  #Fase 1: congelado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nJ56EUBoyJU"
      },
      "source": [
        "*Montar o modelo (cabeça de classificação)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "o95H8Sc_opqG",
        "outputId": "afdec197-f231-4bc6-c5b1-2cbd8e21141b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,715,714\u001b[0m (56.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,715,714</span> (56.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,026\u001b[0m (4.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> (4.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess(x)\n",
        "x = base(x, training=False)                #Mantém training=False com base congelada\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FGGJXYLvo5pp"
      },
      "outputs": [],
      "source": [
        "#Callbacks úteis para treinamento do modelo\n",
        "\n",
        "ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"vgg16_feat_extract.keras\", monitor=\"val_accuracy\",\n",
        "    save_best_only=True, mode=\"max\"\n",
        ")\n",
        "es_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=5, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\"\n",
        ")\n",
        "rlr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.5, patience=2, monitor=\"val_loss\", mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy89G_j-pEg8",
        "outputId": "d657737e-ede1-4c7c-8e19-8931c9b587ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    319/Unknown \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.6148 - loss: 0.6511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 65ms/step - accuracy: 0.6150 - loss: 0.6509 - val_accuracy: 0.8089 - val_loss: 0.4884 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 58ms/step - accuracy: 0.7941 - loss: 0.5009 - val_accuracy: 0.8511 - val_loss: 0.4083 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.8240 - loss: 0.4421 - val_accuracy: 0.8578 - val_loss: 0.3723 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 59ms/step - accuracy: 0.8458 - loss: 0.4010 - val_accuracy: 0.8689 - val_loss: 0.3465 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.8488 - loss: 0.3769 - val_accuracy: 0.8756 - val_loss: 0.3273 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.8480 - loss: 0.3662 - val_accuracy: 0.8778 - val_loss: 0.3154 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - accuracy: 0.8569 - loss: 0.3519 - val_accuracy: 0.8778 - val_loss: 0.3108 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.8650 - loss: 0.3386 - val_accuracy: 0.8844 - val_loss: 0.2977 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.8497 - loss: 0.3488 - val_accuracy: 0.8844 - val_loss: 0.2864 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.8559 - loss: 0.3284 - val_accuracy: 0.8867 - val_loss: 0.2805 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "#Treinar modelo\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[ckpt_cb, es_cb, rlr_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcPAg5WSj5RK"
      },
      "source": [
        "*Métricas de performance*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ALIwsY1Vj3jT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df8a0de-fd5a-46dd-e365-e2722cefb0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8905 - loss: 0.2879\n",
            "Test accuracy: 0.8866666555404663\n",
            "Test lost: 0.2805069386959076\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(val_ds)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "print(\"Test lost:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ge_kEXwOkJP7"
      },
      "outputs": [],
      "source": [
        "#Função para obtenção da imagem\n",
        "def get_image(path):\n",
        "    #Carrega e redimensiona\n",
        "    img = keras.preprocessing.image.load_img(path, target_size=(224, 224))\n",
        "    #Para array (H, W, 3)\n",
        "    x = keras.utils.img_to_array(img)\n",
        "\n",
        "    #Adiciona dimensão de batch: (1, 224, 224, 3)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return img, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eG0SJPyQkbzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fdf8cf-9418-4f70-8f60-98947957f66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693ms/step\n",
            "['Cat', 'Dog']\n",
            "Probabilidades: [[0.64447314 0.35552686]]\n"
          ]
        }
      ],
      "source": [
        "#Teste manual de performance: imagem gato\n",
        "img, x = get_image('/content/drive/MyDrive/Dio.me/Transfer_Learning/teste_gato_meng.jpeg')\n",
        "\n",
        "probs = model.predict(x)\n",
        "print(class_names)\n",
        "print(\"Probabilidades:\", probs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste manual de performance: imagem cachorro\n",
        "img, x = get_image('/content/drive/MyDrive/Dio.me/Transfer_Learning/teste_cachorro_clara.jpeg')\n",
        "\n",
        "probs = model.predict(x)\n",
        "print(class_names)\n",
        "print(\"Probabilidades:\", probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuMhZy_wWY2X",
        "outputId": "01bfe2a4-1ca3-4846-b2d9-50af72a7d880"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "['Cat', 'Dog']\n",
            "Probabilidades: [[0.12839171 0.87160826]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Preparando base de validação*"
      ],
      "metadata": {
        "id": "roVRFIDAvTYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_eval = val_ds.map(lambda x,y: (tf.cast(x, tf.float32), y))\n",
        "val_eval = val_eval.map(lambda x,y: (tf.keras.applications.vgg16.preprocess_input(x), y))\n",
        "\n",
        "# Pega só os rótulos por batch e concatena (cada y tem shape (batch,))\n",
        "y_true = np.concatenate([\n",
        "    y for y in val_eval.map(lambda x,y: y).as_numpy_iterator()\n",
        "])"
      ],
      "metadata": {
        "id": "8gSTXKc8Sgms"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Calculando as métricas*"
      ],
      "metadata": {
        "id": "Ac2xt6bgva53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predições\n",
        "y_prob = model.predict(val_eval, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YoyZRptUKae",
        "outputId": "a7f5f490-ee32-43f8-f0ff-aaa80210d406"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[190  31]\n",
            " [ 23 206]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos que 0 representa a classe \"Cat\" e 1 representa a classe \"Dog\".\n",
        "No cálculo das métricas de recall, acurácia e especificiada, consideraremos que 1 (cachorro) é o valor positivo e 0 (gato) é o valor negativo.\n",
        "\n",
        "Logo:\n",
        "* VP => a imagem é de cachorro e o modelo previu um cachorro\n",
        "* VN => a imagem é de um gato e o modelo previu um gato\n",
        "* FP => a imagem é de um gato e o modelo previu um cachorro\n",
        "* FN => a imagem é de um cachorro e o modelo previu um gato"
      ],
      "metadata": {
        "id": "U2AqpCrtktVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recall\n",
        "#VP/(VP+FN)\n",
        "recall = cm[1,1]/(cm[1,1]+cm[1,0])\n",
        "recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfs1hN12Vhyi",
        "outputId": "2283e1d8-2f37-44a5-8f17-d6d06ae78e7f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8995633187772926)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Acurácia\n",
        "#(VP+VN)/(VP + VN + FP + FP)\n",
        "acuracia = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "acuracia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPjdxIIsYB9s",
        "outputId": "bf81216a-a6f9-4e9d-9494-b0d0c9aa9d39"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.88)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precisão\n",
        "#VP/(VP+FP)\n",
        "precisao = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "precisao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz1XSC9xWqn5",
        "outputId": "b69ee1dd-f662-49ce-c131-3aee734fc752"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.869198312236287)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Especificidade\n",
        "#VN/(VN+FP)\n",
        "especificidade = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "especificidade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmxL9UeyXfKt",
        "outputId": "7156aa87-3286-4b60-ad64-d51eb99efda5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8597285067873304)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#F-score\n",
        "#2(PxS)/(P+S)\n",
        "p = precisao\n",
        "s = especificidade\n",
        "f_score = 2*(p*s)/(p+s)\n",
        "f_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMjB6zlkK93",
        "outputId": "5e44fcb1-7944-4501-d7b0-a21e830252bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8644374751534962)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcaTnw8ppdfr"
      },
      "source": [
        "*Fine-tuning (descongelar topo da VGG16)\n",
        "Descongele algumas camadas superiores para ajustar a base ao seu dataset.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPB7XgHmpdGc",
        "outputId": "27cf5aba-9792-49bc-9c1b-d79c0e315dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    319/Unknown \u001b[1m43s\u001b[0m 118ms/step - accuracy: 0.8942 - loss: 0.2421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 130ms/step - accuracy: 0.8943 - loss: 0.2419 - val_accuracy: 0.9289 - val_loss: 0.1403 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 124ms/step - accuracy: 0.9615 - loss: 0.0987 - val_accuracy: 0.9511 - val_loss: 0.1349 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.9709 - loss: 0.0727 - val_accuracy: 0.9600 - val_loss: 0.0971 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 125ms/step - accuracy: 0.9805 - loss: 0.0527 - val_accuracy: 0.9667 - val_loss: 0.0990 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 123ms/step - accuracy: 0.9813 - loss: 0.0628 - val_accuracy: 0.9556 - val_loss: 0.1161 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 125ms/step - accuracy: 0.9890 - loss: 0.0269 - val_accuracy: 0.9711 - val_loss: 0.0648 - learning_rate: 5.0000e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 123ms/step - accuracy: 0.9950 - loss: 0.0185 - val_accuracy: 0.9689 - val_loss: 0.1146 - learning_rate: 5.0000e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 123ms/step - accuracy: 0.9955 - loss: 0.0143 - val_accuracy: 0.9667 - val_loss: 0.0626 - learning_rate: 5.0000e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 125ms/step - accuracy: 0.9955 - loss: 0.0148 - val_accuracy: 0.9733 - val_loss: 0.0861 - learning_rate: 5.0000e-06\n",
            "Epoch 10/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 123ms/step - accuracy: 0.9949 - loss: 0.0189 - val_accuracy: 0.9711 - val_loss: 0.0688 - learning_rate: 5.0000e-06\n"
          ]
        }
      ],
      "source": [
        "# Descongela a partir de um bloco (ex.: último bloco conv da VGG16)\n",
        "for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "for layer in base.layers[-4*3:]:  # Aprox. últimas 4 camadas conv\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # LR menor no fine-tuning\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_ft = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[ckpt_cb, es_cb, rlr_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vv9HiHRTYpr"
      },
      "source": [
        "*Testes de uso pós fine tunning*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRfh2JIbWXem",
        "outputId": "9cbecb88-567f-4d60-e607-b714c7a86809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "['Cat', 'Dog']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0400799e-10, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Exemplo de uso cachorro\n",
        "img, x = get_image('/content/drive/MyDrive/Dio.me/Transfer_Learning/teste_cachorro_clara.jpeg')\n",
        "probabilities = model.predict(x)\n",
        "print(class_names)\n",
        "probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Jlkl_jW3_Z",
        "outputId": "494ecf04-3351-4586-f61b-08aae6dbe1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "['Cat', 'Dog']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.999169e-01, 8.312655e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Exemplo de uso gato\n",
        "img, x = get_image('/content/drive/MyDrive/Dio.me/Transfer_Learning/teste_gato_gugu.jpeg')\n",
        "probabilities = model.predict(x)\n",
        "\n",
        "print(class_names)\n",
        "probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Calculando novamente as métricas pós fine tuning*"
      ],
      "metadata": {
        "id": "kjspfCYVtlgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QawJIhFXE0l",
        "outputId": "6d353260-7023-49d5-d498-ee5a543f9ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[208  13]\n",
            " [  2 227]]\n"
          ]
        }
      ],
      "source": [
        "# predições\n",
        "y_prob = model.predict(val_eval, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm_pt = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
        "print(cm_pt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recall\n",
        "#VP/(VP+FN)\n",
        "recall_pt = cm_pt[1,1]/(cm_pt[1,1]+cm_pt[1,0])\n",
        "recall_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uGdPKyvrkco",
        "outputId": "661dcb67-acdd-4265-f27f-5c1d5d1f22fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9912663755458515)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M03z5zN0zy3C",
        "outputId": "91921f22-6529-42f3-c6e9-cc5cc84c6c1a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8995633187772926)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Acurácia\n",
        "#(VP+VN)/(VP + VN + FP + FP)\n",
        "acuracia_pt = (cm_pt[0,0] + cm_pt[1,1])/(cm_pt[0,0] + cm_pt[1,1] + cm_pt[0,1] + cm_pt[1,0])\n",
        "acuracia_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShezGnfqt8Br",
        "outputId": "9203402a-794a-4414-8ea3-80c856544ed9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9666666666666667)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acuracia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_bkGFVkz2FL",
        "outputId": "feb3e72b-ce01-44cc-eded-ca2408b5d88b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.88)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precisão\n",
        "#VP/(VP+FP)\n",
        "precisao_pt = cm_pt[1,1]/(cm_pt[1,1]+cm_pt[0,1])\n",
        "precisao_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZLZx7p7uAv6",
        "outputId": "c09b9e88-5668-4fa8-e011-42b1ee33d8d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9458333333333333)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJjR8-Tnz6DP",
        "outputId": "5d9502f5-8897-437e-c660-445612638c4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.869198312236287)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Especificidade\n",
        "#VN/(VN+FP)\n",
        "especificidade_pt = cm_pt[0,0]/(cm_pt[0,0]+cm_pt[0,1])\n",
        "especificidade_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufBd1zhruPMC",
        "outputId": "85a1242e-4146-43e2-a68a-f875c10171c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9411764705882353)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "especificidade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEY7-FYwz86I",
        "outputId": "67e7c94e-8b4a-4d89-85ff-4374d3defadd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8597285067873304)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3FOyP9ez-tt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1ZQaGK12nDLJ5fsjQniF2ZbOmhsI7DOTh",
      "authorship_tag": "ABX9TyPOOqvqJOdBpAoY5cRb7H0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}